{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-14T20:01:38.949397Z","iopub.execute_input":"2022-11-14T20:01:38.949704Z","iopub.status.idle":"2022-11-14T20:01:38.974753Z","shell.execute_reply.started":"2022-11-14T20:01:38.949634Z","shell.execute_reply":"2022-11-14T20:01:38.973962Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import time\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport IPython.display as ipd\n\nfrom scipy.io import wavfile as wav\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras import regularizers\nimport tensorflow.keras as keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint,LearningRateScheduler, Callback\n\nimport plotly.graph_objects as go","metadata":{"execution":{"iopub.status.busy":"2022-11-14T20:01:39.019175Z","iopub.execute_input":"2022-11-14T20:01:39.019421Z","iopub.status.idle":"2022-11-14T20:01:45.363569Z","shell.execute_reply.started":"2022-11-14T20:01:39.019398Z","shell.execute_reply":"2022-11-14T20:01:45.362602Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def Alice(plaintext_length, fc_layers = 1, activation = \"sigmoid\"):\n    N = plaintext_length\n    plaintext_in = Input((N, ), name = \"plaintext_input\")\n    key_in = Input((N, ), name = \"key_input\")\n    x = concatenate([plaintext_in, key_in])\n    for i in range(fc_layers):\n        x = Dense(2 * N, activation = activation)(x)\n    x = tf.expand_dims(x, -1)\n    x = Conv1D(2, 4, strides = 1, padding = \"same\", activation = activation)(x)\n    x = Conv1D(4, 2, strides = 2, padding = \"same\", activation = activation)(x)\n    x = Conv1D(4, 1, strides = 1, padding = \"same\", activation = activation)(x)\n    x = Conv1D(1, 1, strides = 1, padding = \"same\", activation = \"tanh\")(x)\n    outputs = tf.squeeze(x, axis = -1)\n    model = keras.Model(inputs = [plaintext_in, key_in], outputs = outputs)\n    return model\n\ndef Bob(ciphertext_length, fc_layers = 1, activation = \"sigmoid\"):\n    N = ciphertext_length\n    ciphertext_in = Input((N, ), name = \"ciphertext_input\")\n    key_in = Input((N, ), name = \"key_input\")\n    x = concatenate([ciphertext_in, key_in])\n    for i in range(fc_layers):\n        x = Dense(2 * N, activation = activation)(x)\n    \n    x = tf.expand_dims(x, -1)\n    x = Conv1D(2, 4, strides = 1, padding = \"same\", activation = activation)(x)\n    x = Conv1D(4, 2, strides = 2, padding = \"same\", activation = activation)(x)\n    x = Conv1D(4, 1, strides = 1, padding = \"same\", activation = activation)(x)\n    x = Conv1D(1, 1, strides = 1, padding = \"same\", activation = \"tanh\")(x)\n    outputs = tf.squeeze(x, axis = -1)\n    model = keras.Model(inputs = [plaintext_in, key_in], outputs = outputs)\n    return model\n\ndef Eve(plaintext_length, fc_layers = 1, activation = \"sigmoid\"):\n    N = plaintext_length\n    ciphertext_in = Input((N, ), name = \"ciphertext_input\")\n    \n    x = ciphertext_in\n    for i in range(fc_layers):\n        x = Dense(2 * N, activation = activation)(x)\n        \n    x = tf.expand_dims(x, axis = -1)\n    x = Conv1D(2, 4, strides = 1, padding = \"same\", activation = activation)(x)\n    x = Conv1D(4, 2, strides = 2, padding = \"same\", activation = activation)(x)\n    x = Conv1D(4, 1, strides = 1, padding = \"same\", activation = activation)(x)\n    x = Conv1D(1, 1, strides = 1, padding = \"same\", activation = \"tanh\")(x)\n    outputs = tf.squeeze(x, axis = -1)\n    model = keras.Model(inputs = [plaintext_in, key_in], outputs = outputs)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-11-14T20:13:35.955689Z","iopub.execute_input":"2022-11-14T20:13:35.956092Z","iopub.status.idle":"2022-11-14T20:13:35.973860Z","shell.execute_reply.started":"2022-11-14T20:13:35.956041Z","shell.execute_reply":"2022-11-14T20:13:35.972874Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"L1_loss = keras.losses.MeanAbsoluteError()\n\ndef alice_bob_loss(y, y_pred, N, eve_loss):\n    L1_comp = L1_loss(y, y_pred)\n    eve_comp = (N**2 - tf.square(eve_loss)) / (N**2)\n    \n    return L1_comp + eve_comp\n\ndef train(plaintext, key, alice, bob, eve, learning_rate):\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_experiment()","metadata":{},"execution_count":null,"outputs":[]}]}